{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45895c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8ccb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv(\"SMSSpamCollection.csv\",sep='\\t',header=None,names=[\"Label\",\"Message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984729c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e856ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Label    5572 non-null   object\n",
      " 1   Message  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "spam_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a026f",
   "metadata": {},
   "source": [
    "## P(SPAM/SMS) = (P(SMS/SPAM)*P(SPAM)) / P(SMS)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ffe31dfb",
   "metadata": {},
   "source": [
    "# Randomize the dataset\n",
    "# Return a random sample of items from an axis of object.\n",
    "  data_randomized = spam_data.sample(frac=1, random_state=1)\n",
    "# Calculate index for split\n",
    "  training_test_index = round(len(data_randomized) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebd91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(spam_data[\"Message\"])):\n",
    "    spam_data[\"Message\"][i]=spam_data[\"Message\"][i].lower() # lower the message\n",
    "    sentences = nltk.sent_tokenize(spam_data[\"Message\"][i]) #extract the sentences\n",
    "    for j in range(len(sentences)):\n",
    "        spam_data[\"Message\"][i]=re.sub('[^a-zA-Z]',' ', sentences[j]) #remove un necessary punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b3049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=spam_data[\"Message\"]\n",
    "y=spam_data[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4862cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf2b177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_Train 4457\n",
      "Length of Y_Train 4457\n",
      "Length of X_Test 1115\n",
      "Length of Y_Test 1115\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of X_Train\",len(X_train))\n",
    "print(\"Length of Y_Train\",len(y_train))\n",
    "print(\"Length of X_Test\",len(X_test))\n",
    "print(\"Length of Y_Test\",len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f057644",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a930798",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Label': y_train, 'Message': X_train}\n",
    "training_dateset = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee59421",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dateset.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce64d6",
   "metadata": {},
   "source": [
    "## Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bed9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Label': y_test, 'Message': X_test}\n",
    "testing_dateset = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bd6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dateset.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eef722",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455bd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a corpus based on the words in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd6c1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words=[]\n",
    "for i in range(len(training_dateset[\"Message\"])):\n",
    "    words = training_dateset[\"Message\"][i].split()\n",
    "    corpus_words.extend(words)\n",
    "    training_dateset[\"Message\"][i]=training_dateset[\"Message\"][i].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c650c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of corpus words is 5089\n"
     ]
    }
   ],
   "source": [
    "corpus = set(corpus_words)\n",
    "corpus_len= len(corpus)\n",
    "print(\"Total length of corpus words is\",corpus_len)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4f36d17",
   "metadata": {},
   "source": [
    "#Bag of words\n",
    "\n",
    "# for unique word in corpus \n",
    "# create a dictionary of word --> [0 0 0 0 0...0] this list should be of the len(spam messages)\n",
    "# iterate through each message..> take each word from message and put binary 1 against the word\n",
    "# ex: \n",
    "________________________\n",
    "#       | s1  s2 s3 s4\n",
    "________|_______________\n",
    "# go    | 1   0  1  0\n",
    "# until | 0   1  1  0\n",
    "# class | 1   0  1  0\n",
    "# hello | 1   1  0  0\n",
    "\n",
    "# we are bsically creating a mapping of whether a word is present in spam_data[\"Message\"][i] or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "902565c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_dateset[\"Message\"]) for unique_word in corpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c33af5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sms in enumerate(training_dateset['Message']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] = 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d7487df",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be8943c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>orc</th>\n",
       "      <th>fast</th>\n",
       "      <th>philosophy</th>\n",
       "      <th>panalam</th>\n",
       "      <th>calls</th>\n",
       "      <th>li</th>\n",
       "      <th>rply</th>\n",
       "      <th>winaweek</th>\n",
       "      <th>...</th>\n",
       "      <th>throw</th>\n",
       "      <th>decimal</th>\n",
       "      <th>staff</th>\n",
       "      <th>website</th>\n",
       "      <th>her</th>\n",
       "      <th>renewal</th>\n",
       "      <th>er</th>\n",
       "      <th>outsider</th>\n",
       "      <th>woozles</th>\n",
       "      <th>raining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[he, will, you, guys, close]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[can, i, please, come, up, now, imin, town, do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 5091 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message  orc  fast  \\\n",
       "0   ham                       [he, will, you, guys, close]    0     0   \n",
       "1   ham  [can, i, please, come, up, now, imin, town, do...    0     0   \n",
       "\n",
       "   philosophy  panalam  calls  li  rply  winaweek  ...  throw  decimal  staff  \\\n",
       "0           0        0      0   0     0         0  ...      0        0      0   \n",
       "1           0        0      0   0     0         0  ...      0        0      0   \n",
       "\n",
       "   website  her  renewal  er  outsider  woozles  raining  \n",
       "0        0    0        0   0         0        0        0  \n",
       "1        0    0        0   0         0        0        0  \n",
       "\n",
       "[2 rows x 5091 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dateset_new = pd.concat([training_dateset, word_counts], axis=1)\n",
    "training_dateset_new.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd9be2",
   "metadata": {},
   "source": [
    "### verify if the bag of words are correct are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfe5654b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>he</th>\n",
       "      <th>will</th>\n",
       "      <th>you</th>\n",
       "      <th>guys</th>\n",
       "      <th>can</th>\n",
       "      <th>i</th>\n",
       "      <th>please</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[he, will, you, guys, close]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[can, i, please, come, up, now, imin, town, do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ok, k, sry, i, knw, siva, tats, y, i, askd]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[i, ll, see, but, prolly, yeah]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message  he  will  you  guys  \\\n",
       "0                       [he, will, you, guys, close]   1     1    1     1   \n",
       "1  [can, i, please, come, up, now, imin, town, do...   0     0    0     0   \n",
       "2       [ok, k, sry, i, knw, siva, tats, y, i, askd]   0     0    0     0   \n",
       "3                    [i, ll, see, but, prolly, yeah]   0     0    0     0   \n",
       "\n",
       "   can  i  please  \n",
       "0    0  0       0  \n",
       "1    1  1       1  \n",
       "2    0  1       0  \n",
       "3    0  1       0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dateset_new[[\"Message\",\"he\",\"will\",\"you\",\"guys\",\"can\",\"i\",\"please\"]].loc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49102af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code the soam filter based on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ffc802",
   "metadata": {},
   "source": [
    "P(SPAM/given a word wi) = P(Wi/SPAM)*P(SPAM) /  P(wi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d3e46",
   "metadata": {},
   "source": [
    "P(wi/SPAM) = (no of spam messgaes containing this word)+alpha/(total no of spam messages+alpha*corpus_len)\n",
    "\n",
    "alpha = laplacian smoothening factor\n",
    "\n",
    "P(wi/HAM) = (no of ham messgaes containing this word)+alpha/(total no of ham messages+alpha*corpus_len)\n",
    "\n",
    "alpha = laplacian smoothening factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b017e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of spam 0.13417096701817366\n",
      "Probability of ham 0.8658290329818263\n"
     ]
    }
   ],
   "source": [
    "spam_messages = training_dateset_new[training_dateset_new[\"Label\"]==\"spam\"]\n",
    "ham_messages = training_dateset_new[training_dateset_new[\"Label\"]==\"ham\"]\n",
    "\n",
    "Probability_SPAM = len(spam_messages) / len(training_dateset_new)\n",
    "Probability_HAM = len(ham_messages) / len(training_dateset_new)\n",
    "\n",
    "n_spam = len(spam_messages)\n",
    "n_ham = len(ham_messages)\n",
    "alpha = 1\n",
    "\n",
    "print(\"Probability of spam\", Probability_SPAM)\n",
    "print(\"Probability of ham\", Probability_HAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9dd7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate P(wi/SPAM) and P(wi/HAM)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95a85a98",
   "metadata": {},
   "source": [
    "for each word in corpus_words we need to calculate the P(wi/SPAM) and P(wi/HAM)\n",
    "probability_spam_words = P(wi/SPAM)*P(SPAM) \n",
    "probability_ham_words = P(wi/HAM)*P(HAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3892023",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_spam = {unique_word:[0] for unique_word in corpus_words}\n",
    "parameters_ham = {unique_word:[0] for unique_word in corpus_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8f28465",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in corpus_words:\n",
    "    #P(unique_word/givenspam)\n",
    "    unique_word_count_in_spam = spam_messages[word].sum()\n",
    "    prob_word_given_spam = (unique_word_count_in_spam + alpha) / (n_spam + alpha*corpus_len)\n",
    "    parameters_spam[word] = prob_word_given_spam\n",
    "    \n",
    "    #P(unique_word/givenham)\n",
    "    unique_word_count_in_ham = ham_messages[word].sum()\n",
    "    prob_word_given_ham = (unique_word_count_in_ham + alpha) / (n_ham + alpha*corpus_len)\n",
    "    parameters_ham[word] = prob_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693d52a",
   "metadata": {},
   "source": [
    "### create a classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35265b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_classification(message):\n",
    "    #data cleaning\n",
    "    # lower the message\n",
    "    message = message.lower().split()  \n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message = parameters_spam[word]*Probability_SPAM\n",
    "\n",
    "        if word in parameters_ham: \n",
    "            p_ham_given_message  = parameters_ham[word]*Probability_HAM\n",
    "    \n",
    "    prob_total = p_spam_given_message+p_ham_given_message\n",
    "    \n",
    "    p_spam_given_message = (p_spam_given_message)/(prob_total)\n",
    "    p_ham_given_message = (p_ham_given_message)/(prob_total)\n",
    "    \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17f5be5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 0.010961242412235202\n",
      "P(Ham|message): 0.9890387575877647\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "spam_classification(\"Hi.. how are you? I am fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0ce3b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 0.5059394938530497\n",
      "P(Ham|message): 0.4940605061469503\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "spam_classification(\"Hurray.. secret code to win\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6472e31a",
   "metadata": {},
   "source": [
    "### testing this classifier on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee3227b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_classification_test(message):\n",
    "    #data cleaning\n",
    "    #lower the message\n",
    "    message = message.lower().split() \n",
    "    \n",
    "    p_spam_given_message = Probability_SPAM\n",
    "    p_ham_given_message = Probability_HAM\n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message = parameters_spam[word]*p_spam_given_message\n",
    "        if word in parameters_ham: \n",
    "            p_ham_given_message  = parameters_ham[word]*p_ham_given_message\n",
    "    \n",
    "    prob_total = p_spam_given_message+ p_ham_given_message\n",
    "    \n",
    "    p_spam_given_message = (p_spam_given_message)/(prob_total)\n",
    "    p_ham_given_message = (p_ham_given_message)/(prob_total)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return \"ham\"\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"needs human intervention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdde3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dateset[\"Predicted\"] = testing_dateset[\"Message\"].apply(spam_classification_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76e2fe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>no need to buy lunch for me   i eat maggi mee</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>love me xxx</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>reach home already</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>to claim  call</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you r   home then come down within   min</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                          Message Predicted\n",
       "0   ham  no need to buy lunch for me   i eat maggi mee         ham\n",
       "1   ham                                      love me xxx       ham\n",
       "2   ham                              reach home already        ham\n",
       "3  spam                        to claim  call                 spam\n",
       "4   ham      if you r   home then come down within   min       ham"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dateset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4755d2c",
   "metadata": {},
   "source": [
    "### Metrics Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8df5b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_classfied=0\n",
    "wrongly_classfied=0\n",
    "for i in range(len(testing_dateset)):\n",
    "    if(testing_dateset[\"Label\"][i]==testing_dateset[\"Predicted\"][i]):\n",
    "        correctly_classfied+=1\n",
    "    else:\n",
    "        wrongly_classfied+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6675c3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1055\n",
      "Incorrect: 60\n",
      "Accuracy: 0.9461883408071748\n"
     ]
    }
   ],
   "source": [
    "print('Correct:', correctly_classfied)\n",
    "print('Incorrect:', wrongly_classfied)\n",
    "print('Accuracy:', correctly_classfied/len(testing_dateset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
